{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Quantum-inspired baseline (PennyLane + PyTorch)\n",
        "\n",
        "Lightweight demo to benchmark a small hybrid quantum-classical model on Obfuscated-MalMem2022.\n",
        "\n",
        "**Notes**\n",
        "- Designed for ~16GB RAM: samples a small balanced subset and reduces features with PCA.\n",
        "- Runs fully on CPU using PennyLane default.qubit; no real QPU needed.\n",
        "- Goal: get a feel for viability vs. classical baselines (accuracy/F1), not to beat SOTA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pennylane\n",
            "  Using cached pennylane-0.43.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting torch\n",
            "  Using cached torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Requirement already satisfied: scikit-learn in /home/khaitran/project/flmal/.venv/lib/python3.12/site-packages (1.4.2)\n",
            "Requirement already satisfied: pandas in /home/khaitran/project/flmal/.venv/lib/python3.12/site-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /home/khaitran/project/flmal/.venv/lib/python3.12/site-packages (1.26.4)\n",
            "Requirement already satisfied: scipy in /home/khaitran/project/flmal/.venv/lib/python3.12/site-packages (from pennylane) (1.16.3)\n",
            "Collecting networkx (from pennylane)\n",
            "  Using cached networkx-3.6-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting rustworkx>=0.14.0 (from pennylane)\n",
            "  Using cached rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting autograd (from pennylane)\n",
            "  Using cached autograd-1.8.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting appdirs (from pennylane)\n",
            "  Using cached appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting autoray==0.8.0 (from pennylane)\n",
            "  Using cached autoray-0.8.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: cachetools in /home/khaitran/project/flmal/.venv/lib/python3.12/site-packages (from pennylane) (6.2.2)\n",
            "Collecting pennylane-lightning>=0.43 (from pennylane)\n",
            "  Using cached pennylane_lightning-0.43.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: requests in /home/khaitran/project/flmal/.venv/lib/python3.12/site-packages (from pennylane) (2.32.5)\n",
            "Collecting tomlkit (from pennylane)\n",
            "  Using cached tomlkit-0.13.3-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: typing_extensions in /home/khaitran/project/flmal/.venv/lib/python3.12/site-packages (from pennylane) (4.15.0)\n",
            "Requirement already satisfied: packaging in /home/khaitran/project/flmal/.venv/lib/python3.12/site-packages (from pennylane) (25.0)\n",
            "Collecting diastatic-malt (from pennylane)\n",
            "  Using cached diastatic_malt-2.15.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: filelock in /home/khaitran/project/flmal/.venv/lib/python3.12/site-packages (from torch) (3.20.0)\n",
            "Collecting setuptools (from torch)\n",
            "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting sympy>=1.13.3 (from torch)\n",
            "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: jinja2 in /home/khaitran/project/flmal/.venv/lib/python3.12/site-packages (from torch) (3.1.6)\n",
            "Collecting fsspec>=0.8.5 (from torch)\n",
            "  Using cached fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch)\n",
            "  Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Collecting nvidia-nccl-cu12==2.27.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch)\n",
            "  Using cached nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch)\n",
            "  Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.5.1 (from torch)\n",
            "  Using cached triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /home/khaitran/project/flmal/.venv/lib/python3.12/site-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/khaitran/project/flmal/.venv/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/khaitran/project/flmal/.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/khaitran/project/flmal/.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/khaitran/project/flmal/.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
            "Collecting scipy-openblas32>=0.3.26 (from pennylane-lightning>=0.43->pennylane)\n",
            "  Using cached scipy_openblas32-0.3.30.0.8-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (57 kB)\n",
            "Requirement already satisfied: six>=1.5 in /home/khaitran/project/flmal/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting astunparse (from diastatic-malt->pennylane)\n",
            "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting gast (from diastatic-malt->pennylane)\n",
            "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting termcolor (from diastatic-malt->pennylane)\n",
            "  Using cached termcolor-3.2.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/khaitran/project/flmal/.venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /home/khaitran/project/flmal/.venv/lib/python3.12/site-packages (from requests->pennylane) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/khaitran/project/flmal/.venv/lib/python3.12/site-packages (from requests->pennylane) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/khaitran/project/flmal/.venv/lib/python3.12/site-packages (from requests->pennylane) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/khaitran/project/flmal/.venv/lib/python3.12/site-packages (from requests->pennylane) (2025.11.12)\n",
            "Collecting wheel<1.0,>=0.23.0 (from astunparse->diastatic-malt->pennylane)\n",
            "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Using cached pennylane-0.43.1-py3-none-any.whl (5.3 MB)\n",
            "Using cached autoray-0.8.0-py3-none-any.whl (934 kB)\n",
            "Using cached torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (899.7 MB)\n",
            "Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
            "Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
            "Using cached nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "Using cached nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "Using cached triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n",
            "Using cached fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
            "Using cached networkx-3.6-py3-none-any.whl (2.1 MB)\n",
            "Using cached pennylane_lightning-0.43.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (2.5 MB)\n",
            "Using cached rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Using cached autograd-1.8.0-py3-none-any.whl (51 kB)\n",
            "Using cached diastatic_malt-2.15.2-py3-none-any.whl (167 kB)\n",
            "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "Using cached tomlkit-0.13.3-py3-none-any.whl (38 kB)\n",
            "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Using cached scipy_openblas32-0.3.30.0.8-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.6 MB)\n",
            "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
            "Using cached termcolor-3.2.0-py3-none-any.whl (7.7 kB)\n",
            "Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "Installing collected packages: nvidia-cusparselt-cu12, mpmath, appdirs, wheel, triton, tomlkit, termcolor, sympy, setuptools, scipy-openblas32, rustworkx, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, gast, fsspec, autoray, autograd, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, astunparse, nvidia-cusolver-cu12, diastatic-malt, torch, pennylane-lightning, pennylane\n",
            "Successfully installed appdirs-1.4.4 astunparse-1.6.3 autograd-1.8.0 autoray-0.8.0 diastatic-malt-2.15.2 fsspec-2025.10.0 gast-0.6.0 mpmath-1.3.0 networkx-3.6 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 pennylane-0.43.1 pennylane-lightning-0.43.0 rustworkx-0.17.1 scipy-openblas32-0.3.30.0.8 setuptools-80.9.0 sympy-1.14.0 termcolor-3.2.0 tomlkit-0.13.3 torch-2.9.1 triton-3.5.1 wheel-0.45.1\n"
          ]
        }
      ],
      "source": [
        "# If needed, install deps (uncomment):\n",
        "!pip install pennylane torch scikit-learn pandas numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import pennylane as qml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_38458/1134695053.py:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda g: g.sample(min(len(g), N_SAMPLES_PER_CLASS), random_state=42))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subset size 20000 Train 16000 Test 4000\n"
          ]
        }
      ],
      "source": [
        "# Config\n",
        "DATA_PATH = Path(\"Obfuscated-MalMem2022.csv\")\n",
        "if not DATA_PATH.exists():\n",
        "    DATA_PATH = Path(\"..\").joinpath(\"Obfuscated-MalMem2022.csv\")\n",
        "N_SAMPLES_PER_CLASS = 10000  # small to fit in 16GB; adjust as needed\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 30\n",
        "LR = 1e-3\n",
        "N_QUBITS = 4  # keep small; matches PCA components\n",
        "\n",
        "# Load\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "df['label'] = df['Class'].apply(lambda c: 0 if str(c).lower() == 'benign' else 1)\n",
        "\n",
        "# Balanced small subset\n",
        "subset = (\n",
        "    df.groupby('label', group_keys=False)\n",
        "    .apply(lambda g: g.sample(min(len(g), N_SAMPLES_PER_CLASS), random_state=42))\n",
        "    .sample(frac=1.0, random_state=42)\n",
        ")\n",
        "\n",
        "X = subset.drop(columns=['Class', 'Category', 'label'], errors='ignore').to_numpy(dtype=np.float32)\n",
        "y = subset['label'].to_numpy(dtype=np.int64)\n",
        "\n",
        "# Scale + reduce\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "pca = PCA(n_components=N_QUBITS, random_state=42)\n",
        "X_enc = pca.fit_transform(X_scaled).astype(np.float32)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_enc, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "train_ds = TensorDataset(torch.tensor(X_train), torch.tensor(y_train))\n",
        "test_ds = TensorDataset(torch.tensor(X_test), torch.tensor(y_test))\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE)\n",
        "\n",
        "print(\"Subset size\", len(subset), \"Train\", len(train_ds), \"Test\", len(test_ds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quantum layer via PennyLane TorchLayer\n",
        "dev = qml.device(\"default.qubit\", wires=N_QUBITS)\n",
        "\n",
        "def angle_encoding(x, wires):\n",
        "    for i, w in enumerate(wires):\n",
        "        qml.RX(x[i], wires=w)\n",
        "\n",
        "def variational_block(weights, wires):\n",
        "    # Simple hardware-efficient ansatz\n",
        "    for i, w in enumerate(wires):\n",
        "        qml.RY(weights[i], wires=w)\n",
        "    for i in range(len(wires) - 1):\n",
        "        qml.CNOT(wires=[wires[i], wires[i + 1]])\n",
        "    qml.CNOT(wires=[wires[-1], wires[0]])\n",
        "\n",
        "def qnode_fn(inputs, weights):\n",
        "    angle_encoding(inputs, wires=range(N_QUBITS))\n",
        "    variational_block(weights, wires=range(N_QUBITS))\n",
        "    return [qml.expval(qml.PauliZ(i)) for i in range(N_QUBITS)]\n",
        "\n",
        "weight_shapes = {\"weights\": (N_QUBITS,)}\n",
        "qnode = qml.QNode(qnode_fn, dev, interface=\"torch\", diff_method=\"backprop\")\n",
        "qlayer = qml.qnn.TorchLayer(qnode, weight_shapes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HybridModel(\n",
            "  (classical): Sequential(\n",
            "    (0): Linear(in_features=4, out_features=4, bias=True)\n",
            "    (1): ReLU()\n",
            "  )\n",
            "  (quantum): <Quantum Torch Layer: func=qnode_fn>\n",
            "  (head): Linear(in_features=4, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class HybridModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.classical = nn.Sequential(\n",
        "            nn.Linear(N_QUBITS, N_QUBITS),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.quantum = qlayer\n",
        "        self.head = nn.Linear(N_QUBITS, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.classical(x)\n",
        "        # TorchLayer in this version doesn't batch internally; loop over batch\n",
        "        q_out = torch.stack([self.quantum(xi) for xi in x])\n",
        "        x = self.head(q_out)\n",
        "        return torch.sigmoid(x)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = HybridModel().to(device)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: loss=0.7180 test_acc=0.5000 f1=0.3333\n",
            "Epoch 2: loss=0.7078 test_acc=0.5000 f1=0.3333\n",
            "Epoch 3: loss=0.7020 test_acc=0.5000 f1=0.3333\n",
            "Epoch 4: loss=0.6986 test_acc=0.5000 f1=0.3333\n",
            "Epoch 5: loss=0.6957 test_acc=0.5000 f1=0.3333\n",
            "Epoch 6: loss=0.6920 test_acc=0.5000 f1=0.3333\n",
            "Epoch 7: loss=0.6844 test_acc=0.4775 f1=0.3273\n",
            "Epoch 8: loss=0.6659 test_acc=0.6825 f1=0.6609\n",
            "Epoch 9: loss=0.6286 test_acc=0.8525 f1=0.8518\n",
            "Epoch 10: loss=0.5725 test_acc=0.8975 f1=0.8974\n",
            "Epoch 11: loss=0.5105 test_acc=0.9050 f1=0.9050\n",
            "Epoch 12: loss=0.4548 test_acc=0.9075 f1=0.9075\n",
            "Epoch 13: loss=0.4104 test_acc=0.9200 f1=0.9200\n",
            "Epoch 14: loss=0.3762 test_acc=0.9275 f1=0.9275\n",
            "Epoch 15: loss=0.3500 test_acc=0.9275 f1=0.9275\n",
            "Epoch 16: loss=0.3299 test_acc=0.9275 f1=0.9275\n",
            "Epoch 17: loss=0.3114 test_acc=0.9250 f1=0.9250\n",
            "Epoch 18: loss=0.2964 test_acc=0.9325 f1=0.9325\n",
            "Epoch 19: loss=0.2845 test_acc=0.9325 f1=0.9325\n",
            "Epoch 20: loss=0.2752 test_acc=0.9325 f1=0.9325\n",
            "Epoch 21: loss=0.2670 test_acc=0.9325 f1=0.9325\n",
            "Epoch 22: loss=0.2602 test_acc=0.9325 f1=0.9325\n",
            "Epoch 23: loss=0.2542 test_acc=0.9350 f1=0.9350\n",
            "Epoch 24: loss=0.2491 test_acc=0.9350 f1=0.9350\n",
            "Epoch 25: loss=0.2440 test_acc=0.9350 f1=0.9350\n",
            "Epoch 26: loss=0.2392 test_acc=0.9350 f1=0.9350\n",
            "Epoch 27: loss=0.2351 test_acc=0.9400 f1=0.9400\n",
            "Epoch 28: loss=0.2318 test_acc=0.9375 f1=0.9375\n",
            "Epoch 29: loss=0.2286 test_acc=0.9400 f1=0.9400\n",
            "Epoch 30: loss=0.2256 test_acc=0.9375 f1=0.9375\n"
          ]
        }
      ],
      "source": [
        "def train_epoch(loader):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for xb, yb in loader:\n",
        "        xb, yb = xb.to(device), yb.to(device).float().unsqueeze(1)\n",
        "        opt.zero_grad()\n",
        "        preds = model(xb)\n",
        "        loss = loss_fn(preds, yb)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        total_loss += loss.item() * len(xb)\n",
        "    return total_loss / len(loader.dataset)\n",
        "\n",
        "def eval_epoch(loader):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in loader:\n",
        "            xb = xb.to(device)\n",
        "            preds = model(xb).cpu().numpy().ravel()\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(yb.numpy())\n",
        "    all_preds = np.array(all_preds)\n",
        "    all_labels = np.array(all_labels)\n",
        "    pred_labels = (all_preds >= 0.5).astype(int)\n",
        "    report = classification_report(all_labels, pred_labels, target_names=[\"benign\", \"malware\"], output_dict=True, zero_division=0)\n",
        "    return report\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train_loss = train_epoch(train_loader)\n",
        "    report = eval_epoch(test_loader)\n",
        "    print(f\"Epoch {epoch}: loss={train_loss:.4f} test_acc={report['accuracy']:.4f} f1={report['weighted avg']['f1-score']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>benign</th>\n",
              "      <td>0.953368</td>\n",
              "      <td>0.9200</td>\n",
              "      <td>0.936387</td>\n",
              "      <td>200.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>malware</th>\n",
              "      <td>0.922705</td>\n",
              "      <td>0.9550</td>\n",
              "      <td>0.938575</td>\n",
              "      <td>200.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>accuracy</th>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.9375</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.9375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>macro avg</th>\n",
              "      <td>0.938037</td>\n",
              "      <td>0.9375</td>\n",
              "      <td>0.937481</td>\n",
              "      <td>400.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weighted avg</th>\n",
              "      <td>0.938037</td>\n",
              "      <td>0.9375</td>\n",
              "      <td>0.937481</td>\n",
              "      <td>400.0000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              precision  recall  f1-score   support\n",
              "benign         0.953368  0.9200  0.936387  200.0000\n",
              "malware        0.922705  0.9550  0.938575  200.0000\n",
              "accuracy       0.937500  0.9375  0.937500    0.9375\n",
              "macro avg      0.938037  0.9375  0.937481  400.0000\n",
              "weighted avg   0.938037  0.9375  0.937481  400.0000"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Final report\n",
        "final_report = eval_epoch(test_loader)\n",
        "pd.DataFrame(final_report).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Quantum variants: QMLP and QCNN\n",
        "Lightweight circuits for comparison. Keep epochs small to fit 16GB RAM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Builders for quantum MLP and quantum CNN-style circuits\n",
        "\n",
        "import pennylane as qml\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "def make_qmlp_layer(n_qubits, layers=1):\n",
        "    dev = qml.device('default.qubit', wires=n_qubits)\n",
        "\n",
        "    @qml.qnode(dev, interface='torch', diff_method='backprop')\n",
        "    def circuit(inputs, weights):\n",
        "        qml.AngleEmbedding(inputs, wires=range(n_qubits))\n",
        "        qml.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "        return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
        "\n",
        "    weight_shapes = {'weights': (layers, n_qubits)}\n",
        "    return qml.qnn.TorchLayer(circuit, weight_shapes)\n",
        "\n",
        "\n",
        "def make_qcnn_layer(n_qubits, layers=1):\n",
        "    dev = qml.device('default.qubit', wires=n_qubits)\n",
        "\n",
        "    @qml.qnode(dev, interface='torch', diff_method='backprop')\n",
        "    def circuit(inputs, weights):\n",
        "        qml.AngleEmbedding(inputs, wires=range(n_qubits))\n",
        "        # simple conv-like entangling: pairwise CX + RY\n",
        "        for l in range(layers):\n",
        "            for i in range(n_qubits):\n",
        "                qml.CNOT(wires=[i, (i+1)%n_qubits])\n",
        "                qml.RY(weights[l, i], wires=i)\n",
        "        return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
        "\n",
        "    weight_shapes = {'weights': (layers, n_qubits)}\n",
        "    return qml.qnn.TorchLayer(circuit, weight_shapes)\n",
        "\n",
        "\n",
        "def train_and_eval(model, epochs=4, lr=1e-3):\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    loss_fn = nn.BCELoss()\n",
        "\n",
        "    def _loop(loader, train=True):\n",
        "        if train:\n",
        "            model.train()\n",
        "        else:\n",
        "            model.eval()\n",
        "        total_loss = 0.0\n",
        "        all_preds, all_labels = [], []\n",
        "        with torch.set_grad_enabled(train):\n",
        "            for xb, yb in loader:\n",
        "                xb = xb.to(device)\n",
        "                yb = yb.to(device).float().unsqueeze(1)\n",
        "                if train:\n",
        "                    opt.zero_grad()\n",
        "                preds = model(xb)\n",
        "                loss = loss_fn(preds, yb)\n",
        "                if train:\n",
        "                    loss.backward()\n",
        "                    opt.step()\n",
        "                total_loss += loss.item() * len(xb)\n",
        "                all_preds.extend(preds.detach().cpu().numpy().ravel())\n",
        "                all_labels.extend(yb.cpu().numpy().ravel())\n",
        "        return total_loss / max(len(loader.dataset), 1), np.array(all_preds), np.array(all_labels)\n",
        "\n",
        "    for _ in range(epochs):\n",
        "        train_loss, _, _ = _loop(train_loader, train=True)\n",
        "\n",
        "    _, preds, labels = _loop(test_loader, train=False)\n",
        "    pred_labels = (preds >= 0.5).astype(int)\n",
        "    report = classification_report(\n",
        "        labels, pred_labels, target_names=['benign', 'malware'], output_dict=True, zero_division=0\n",
        "    )\n",
        "    return report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "qmlp accuracy 0.755 f1 0.7547937815703005\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>benign</th>\n",
              "      <td>0.770701</td>\n",
              "      <td>0.726</td>\n",
              "      <td>0.747683</td>\n",
              "      <td>2000.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>malware</th>\n",
              "      <td>0.741021</td>\n",
              "      <td>0.784</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>2000.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>accuracy</th>\n",
              "      <td>0.755000</td>\n",
              "      <td>0.755</td>\n",
              "      <td>0.755000</td>\n",
              "      <td>0.755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>macro avg</th>\n",
              "      <td>0.755861</td>\n",
              "      <td>0.755</td>\n",
              "      <td>0.754794</td>\n",
              "      <td>4000.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weighted avg</th>\n",
              "      <td>0.755861</td>\n",
              "      <td>0.755</td>\n",
              "      <td>0.754794</td>\n",
              "      <td>4000.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              precision  recall  f1-score   support\n",
              "benign         0.770701   0.726  0.747683  2000.000\n",
              "malware        0.741021   0.784  0.761905  2000.000\n",
              "accuracy       0.755000   0.755  0.755000     0.755\n",
              "macro avg      0.755861   0.755  0.754794  4000.000\n",
              "weighted avg   0.755861   0.755  0.754794  4000.000"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "qcnn accuracy 0.5985 f1 0.5980622898336289\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>benign</th>\n",
              "      <td>0.605460</td>\n",
              "      <td>0.5655</td>\n",
              "      <td>0.584798</td>\n",
              "      <td>2000.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>malware</th>\n",
              "      <td>0.592402</td>\n",
              "      <td>0.6315</td>\n",
              "      <td>0.611326</td>\n",
              "      <td>2000.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>accuracy</th>\n",
              "      <td>0.598500</td>\n",
              "      <td>0.5985</td>\n",
              "      <td>0.598500</td>\n",
              "      <td>0.5985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>macro avg</th>\n",
              "      <td>0.598931</td>\n",
              "      <td>0.5985</td>\n",
              "      <td>0.598062</td>\n",
              "      <td>4000.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weighted avg</th>\n",
              "      <td>0.598931</td>\n",
              "      <td>0.5985</td>\n",
              "      <td>0.598062</td>\n",
              "      <td>4000.0000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              precision  recall  f1-score    support\n",
              "benign         0.605460  0.5655  0.584798  2000.0000\n",
              "malware        0.592402  0.6315  0.611326  2000.0000\n",
              "accuracy       0.598500  0.5985  0.598500     0.5985\n",
              "macro avg      0.598931  0.5985  0.598062  4000.0000\n",
              "weighted avg   0.598931  0.5985  0.598062  4000.0000"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Compare QMLP and QCNN\n",
        "def make_qmlp_model():\n",
        "    qlayer = make_qmlp_layer(N_QUBITS, layers=1)\n",
        "    class Model(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__(); self.q = qlayer; self.head = nn.Linear(N_QUBITS,1)\n",
        "        def forward(self, x):\n",
        "            q_out = torch.stack([self.q(xi) for xi in x])\n",
        "            return torch.sigmoid(self.head(q_out))\n",
        "    return Model().to(device)\n",
        "\n",
        "def make_qcnn_model():\n",
        "    qlayer = make_qcnn_layer(N_QUBITS, layers=1)\n",
        "    class Model(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__(); self.q = qlayer; self.head = nn.Linear(N_QUBITS,1)\n",
        "        def forward(self, x):\n",
        "            q_out = torch.stack([self.q(xi) for xi in x])\n",
        "            return torch.sigmoid(self.head(q_out))\n",
        "    return Model().to(device)\n",
        "\n",
        "for name, builder in [('qmlp', make_qmlp_model), ('qcnn', make_qcnn_model)]:\n",
        "    report = train_and_eval(builder(), epochs=5, lr=1e-3)\n",
        "    print(name, 'accuracy', report['accuracy'], 'f1', report['weighted avg']['f1-score'])\n",
        "    display(pd.DataFrame(report).T)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
